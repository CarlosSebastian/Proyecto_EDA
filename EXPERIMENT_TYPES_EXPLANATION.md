# Tipos de Experimentos y Generaci√≥n de CSVs

## üìã Respuestas a tus Preguntas

### 1. ¬øTengo que crear manualmente cada CSV o lo crear√° la p√°gina?

**Respuesta: La p√°gina lo crear√° autom√°ticamente** ‚úÖ

**C√≥mo funcionar√°:**

#### Opci√≥n A: Ejecuci√≥n desde Frontend (Recomendado)
```
1. Usuario configura experimento en la UI
2. Frontend env√≠a request a API backend
3. Backend ejecuta TSTester.exe con par√°metros
4. TSTester.exe genera CSVs autom√°ticamente
5. Backend lee CSVs y devuelve JSON al frontend
6. Frontend muestra resultados y puede generar CSV si lo necesita
```

**Ventajas:**
- ‚úÖ No necesitas crear CSVs manualmente
- ‚úÖ Todo automatizado
- ‚úÖ Historial guardado autom√°ticamente

#### Opci√≥n B: Cargar CSV Existente (Alternativa)
```
1. Si ya tienes CSVs generados, puedes cargarlos
2. Frontend los parsea y muestra
3. √ötil para resultados previos
```

---

### 2. ¬øQu√© tipos de experimentos deber√≠a hacer?

**S√ç, deber√≠a hacer todos estos tests** seg√∫n el paper:

## üß™ Tipos de Experimentos del Paper

### A. Test de Tightness (-t)
**Qu√© hace:**
- Calcula tightness promedio de cada bound
- Tightness = bound_value / true_DTW_distance
- Muestra qu√© tan ajustado es cada bound

**Cu√°ndo usar:**
- Para comparar tightness entre bounds
- Para generar gr√°ficas tipo Figuras 1 y 2 del paper

**Comando:**
```bash
TSTester.exe -t -bkeogh,webb,petitjean -W -d50words,Adiac
```

**Output:**
- `tightness-W.csv` con valores de tightness promedio

---

### B. 1-NN con Ventana √ìptima, UNSORTED (default)
**Qu√© hace:**
- Ejecuta Nearest Neighbor (1-NN)
- Sin ordenar las series de entrenamiento
- 10 iteraciones (promedio)
- Usa ventana √≥ptima para cada dataset

**Cu√°ndo usar:**
- Para comparar tiempos de ejecuci√≥n
- Para ver cu√°ntas series se podan
- Para medir precisi√≥n (accuracy)

**Comando:**
```bash
TSTester.exe -bkeogh,webb -W -d50words,Adiac
# o expl√≠citamente:
TSTester.exe -bkeogh,webb -W -d50words,Adiac  # UNSORTED es default
```

**Output:**
- `times-W-nosort.csv`
- `pruned-W-nosort.csv`
- `accuracy-W-nosort.csv`
- `time-dev-W-nosort.csv`

---

### C. 1-NN con Ventana √ìptima, SORTED (-s)
**Qu√© hace:**
- Ejecuta Nearest Neighbor (1-NN)
- Ordena las series de entrenamiento por lower bound
- 1 iteraci√≥n (ya est√° ordenado)
- Usa ventana √≥ptima

**Cu√°ndo usar:**
- Para ver el efecto de ordenar por bound
- Comparar eficiencia con/sin ordenamiento

**Comando:**
```bash
TSTester.exe -s -bkeogh,webb -W -d50words,Adiac
```

**Output:**
- `times-W-sort.csv`
- `pruned-W-sort.csv`
- `accuracy-W-sort.csv`
- `time-dev-W-sort.csv`

---

### D. Ventanas Fijas (1%, 10%, 20%) (-g)
**Qu√© hace:**
- Ejecuta con ventana como porcentaje de la longitud
- √ötil para ver c√≥mo afecta el tama√±o de ventana

**Cu√°ndo usar:**
- An√°lisis de sensibilidad a tama√±o de ventana
- Comparar diferentes configuraciones

**Comando:**
```bash
# Ventana 1%
TSTester.exe -g1 -bkeogh,webb -d50words,Adiac

# Ventana 10%
TSTester.exe -g10 -bkeogh,webb -d50words,Adiac

# Ventana 20%
TSTester.exe -g20 -bkeogh,webb -d50words,Adiac
```

**Output:**
- `times-g1-nosort.csv`
- `times-g10-nosort.csv`
- `times-g20-nosort.csv`
- etc.

---

## üéØ Qu√© Deber√≠a Hacer el Frontend

### Configuraci√≥n de Experimentos

El frontend deber√≠a permitir seleccionar:

1. **Tipo de Experimento:**
   - ‚òëÔ∏è Tightness Test
   - ‚òëÔ∏è 1-NN UNSORTED
   - ‚òëÔ∏è 1-NN SORTED
   - ‚òëÔ∏è M√∫ltiples tipos (ejecutar todos)

2. **Configuraci√≥n de Ventana:**
   - ‚òëÔ∏è √ìptima (-W)
   - ‚òëÔ∏è Fija (-w n√∫mero)
   - ‚òëÔ∏è Porcentaje (-g 1, 10, 20, etc.)
   - ‚òëÔ∏è M√∫ltiples ventanas (ejecutar todos)

3. **Bounds a Comparar:**
   - ‚òëÔ∏è Multi-select (Keogh, Webb, Petitjean, Improved, etc.)

4. **Datasets:**
   - ‚òëÔ∏è Multi-select de datasets disponibles

---

## üìä Flujo Completo Propuesto

### Escenario: Comparar Webb y Petitjean vs Otros

**Paso 1: Configurar Experimento**
```
Tipo: Tightness + 1-NN UNSORTED + 1-NN SORTED
Ventana: √ìptima
Bounds: Keogh, Webb, Petitjean, Improved
Datasets: 50words, Adiac, CBF, FaceAll, Two_Patterns
```

**Paso 2: Ejecutar (Autom√°tico)**
```
Frontend ‚Üí API ‚Üí Ejecuta 3 experimentos:
1. Tightness test
2. 1-NN UNSORTED
3. 1-NN SORTED
```

**Paso 3: Resultados**
```
- tightness-W.csv
- times-W-nosort.csv
- times-W-sort.csv
- pruned-W-nosort.csv
- pruned-W-sort.csv
- accuracy-W-nosort.csv
- accuracy-W-sort.csv
```

**Paso 4: Visualizar**
```
- Gr√°fica de tightness relativo (desde tightness-W.csv)
- Gr√°fica de tiempos comparativos (desde times-*.csv)
- Tabla comparativa completa
```

---

## üîß Implementaci√≥n en Frontend

### Componente: ExperimentConfigurator

```typescript
interface ExperimentConfig {
  // Tipo de experimento
  experimentTypes: {
    tightness: boolean;
    nnUnsorted: boolean;
    nnSorted: boolean;
  };
  
  // Ventana
  windowConfig: {
    type: 'optimal' | 'fixed' | 'percentage';
    value?: number;  // Para fixed o percentage
    multiple?: number[];  // Para m√∫ltiples porcentajes [1, 10, 20]
  };
  
  // Bounds
  bounds: string[];  // ['keogh', 'webb', 'petitjean']
  
  // Datasets
  datasets: string[];
}
```

### Ejemplo de Uso

```typescript
const config: ExperimentConfig = {
  experimentTypes: {
    tightness: true,
    nnUnsorted: true,
    nnSorted: true
  },
  windowConfig: {
    type: 'optimal'  // -W
  },
  bounds: ['keogh', 'webb', 'petitjean'],
  datasets: ['50words', 'Adiac', 'CBF']
};

// Frontend env√≠a a API
POST /api/experiment/run
{
  ...config
}

// API ejecuta:
// 1. TSTester.exe -t -bkeogh,webb,petitjean -W -d50words,Adiac,CBF
// 2. TSTester.exe -bkeogh,webb,petitjean -W -d50words,Adiac,CBF
// 3. TSTester.exe -s -bkeogh,webb,petitjean -W -d50words,Adiac,CBF
```

---

## ‚úÖ Resumen

### Pregunta 1: ¬øCrear CSVs manualmente?
**NO** - El frontend ejecutar√° TSTester.exe autom√°ticamente y generar√° los CSVs.

### Pregunta 2: ¬øQu√© tests hacer?
**S√ç, todos:**
- ‚úÖ Tightness test
- ‚úÖ 1-NN UNSORTED (ventana √≥ptima)
- ‚úÖ 1-NN SORTED (ventana √≥ptima)
- ‚úÖ Ventanas fijas (1%, 10%, 20%) - opcional pero √∫til

### Beneficios:
1. **Automatizaci√≥n completa** - No necesitas crear CSVs manualmente
2. **Comparaciones completas** - Todos los tipos de experimentos del paper
3. **Flexibilidad** - Puedes elegir qu√© experimentos ejecutar
4. **Historial** - Todo se guarda autom√°ticamente

---

## üöÄ Pr√≥ximos Pasos

1. Frontend permite seleccionar tipos de experimento
2. Frontend env√≠a configuraci√≥n a API
3. API ejecuta TSTester.exe con par√°metros correctos
4. API lee CSVs generados y devuelve JSON
5. Frontend muestra resultados y puede generar CSV si necesita exportar

¬øTe parece bien esta aproximaci√≥n?

